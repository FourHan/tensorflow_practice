{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq-google.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiZ96RwCCs+lYfpCVemB5e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FourHan/tensorflow_practice/blob/master/seq2seq_google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1eu6mKhiyha",
        "colab_type": "code",
        "outputId": "de66fbe7-9f90-4bdb-ee52-dfb2f0c3e4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# 刚开始会提示错误，但是再执行一下就不会出错了\n",
        "!pip install tf-nightly\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.1.0.dev20200109)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.17.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.1.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: tb-nightly<2.3.0a0,>=2.2.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.2.0a20200106)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.2)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.0.0.dev2020010909)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.33.6)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tf-nightly) (42.0.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoaaUV0R1RQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"水电费水电费连接\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybHOB4-XSD0B",
        "colab_type": "code",
        "outputId": "6e235b57-b1b3-4c9a-bb1d-ec0bfc41425e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "tf.__version__   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6D8piAUPopO",
        "colab_type": "code",
        "outputId": "31239239-d30b-4b43-ae85-5858241f4274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.33.6)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.17.5)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KrJDOTPjrIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVOyoBHFi52p",
        "colab_type": "code",
        "outputId": "1224587d-b831-432c-e4b1-ea799076d58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/nmt.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nmt'...\n",
            "remote: Enumerating objects: 1283, done.\u001b[K\n",
            "remote: Total 1283 (delta 0), reused 0 (delta 0), pack-reused 1283\u001b[K\n",
            "Receiving objects: 100% (1283/1283), 1.24 MiB | 1.39 MiB/s, done.\n",
            "Resolving deltas: 100% (918/918), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRkzQzTfkNHl",
        "colab_type": "code",
        "outputId": "da068c0f-5b89-4404-e61e-284bcf5a7c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data1  nmt  nmt1  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W23xiMIhk9mc",
        "colab_type": "code",
        "outputId": "8885ce19-2daa-4702-ff9a-c8cbb20f4a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls nmt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTING.md  LICENSE  nmt  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Z2aDkPlA3i",
        "colab_type": "code",
        "outputId": "d044c23f-064c-496e-da6d-dcaef59e49a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!ls nmt/nmt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attention_model.py  inference_test.py  model_test.py  standard_hparams\n",
            "g3doc\t\t    __init__.py        nmt.py\t      testdata\n",
            "gnmt_model.py\t    model_helper.py    nmt_test.py    train.py\n",
            "inference.py\t    model.py\t       scripts\t      utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP6mrzljlFTh",
        "colab_type": "code",
        "outputId": "feda0247-18c5-4967-c233-9664e7a4933c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "!cat nmt/nmt/scripts/download_iwslt15.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#!/bin/sh\n",
            "# Download small-scale IWSLT15 Vietnames to English translation data for NMT\n",
            "# model training.\n",
            "#\n",
            "# Usage:\n",
            "#   ./download_iwslt15.sh path-to-output-dir\n",
            "#\n",
            "# If output directory is not specified, \"./iwslt15\" will be used as the default\n",
            "# output directory.\n",
            "OUT_DIR=\"${1:-iwslt15}\"\n",
            "SITE_PREFIX=\"https://nlp.stanford.edu/projects/nmt/data\"\n",
            "\n",
            "mkdir -v -p $OUT_DIR\n",
            "\n",
            "# Download iwslt15 small dataset from standford website.\n",
            "echo \"Download training dataset train.en and train.vi.\"\n",
            "curl -o \"$OUT_DIR/train.en\" \"$SITE_PREFIX/iwslt15.en-vi/train.en\"\n",
            "curl -o \"$OUT_DIR/train.vi\" \"$SITE_PREFIX/iwslt15.en-vi/train.vi\"\n",
            "\n",
            "echo \"Download dev dataset tst2012.en and tst2012.vi.\"\n",
            "curl -o \"$OUT_DIR/tst2012.en\" \"$SITE_PREFIX/iwslt15.en-vi/tst2012.en\"\n",
            "curl -o \"$OUT_DIR/tst2012.vi\" \"$SITE_PREFIX/iwslt15.en-vi/tst2012.vi\"\n",
            "\n",
            "echo \"Download test dataset tst2013.en and tst2013.vi.\"\n",
            "curl -o \"$OUT_DIR/tst2013.en\" \"$SITE_PREFIX/iwslt15.en-vi/tst2013.en\"\n",
            "curl -o \"$OUT_DIR/tst2013.vi\" \"$SITE_PREFIX/iwslt15.en-vi/tst2013.vi\"\n",
            "\n",
            "echo \"Download vocab file vocab.en and vocab.vi.\"\n",
            "curl -o \"$OUT_DIR/vocab.en\" \"$SITE_PREFIX/iwslt15.en-vi/vocab.en\"\n",
            "curl -o \"$OUT_DIR/vocab.vi\" \"$SITE_PREFIX/iwslt15.en-vi/vocab.vi\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHB54FW6lPab",
        "colab_type": "code",
        "outputId": "a966e780-0af8-47af-c708-d5711e964a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "!nmt/nmt/scripts/download_iwslt15.sh ./data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: created directory './data'\n",
            "Download training dataset train.en and train.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12.9M  100 12.9M    0     0  2308k      0  0:00:05  0:00:05 --:--:-- 3225k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 17.2M  100 17.2M    0     0  2903k      0  0:00:06  0:00:06 --:--:-- 4190k\n",
            "Download dev dataset tst2012.en and tst2012.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0    99k      0  0:00:01  0:00:01 --:--:--   99k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  183k  100  183k    0     0   121k      0  0:00:01  0:00:01 --:--:--  121k\n",
            "Download test dataset tst2013.en and tst2013.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  129k  100  129k    0     0    99k      0  0:00:01  0:00:01 --:--:--   99k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  179k  100  179k    0     0   119k      0  0:00:01  0:00:01 --:--:--  119k\n",
            "Download vocab file vocab.en and vocab.vi.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  136k  100  136k    0     0    97k      0  0:00:01  0:00:01 --:--:--   97k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 46767  100 46767    0     0  56210      0 --:--:-- --:--:-- --:--:-- 56142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xIalFbfldQ0",
        "colab_type": "code",
        "outputId": "dda8d69a-618f-4dd4-e243-159c9b913a1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  data1  nmt  nmt1\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXkXQv9SloJ8",
        "colab_type": "code",
        "outputId": "10fa2f1a-8e05-4596-fa0e-cff288ddb609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.en  tst2012.en  tst2013.en  vocab.en\n",
            "train.vi  tst2012.vi  tst2013.vi  vocab.vi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKH4Iznalsid",
        "colab_type": "code",
        "outputId": "c0b49617-8173-435d-bfde-49459c4a3143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!head  -10 data/train.en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rachel Pike : The science behind a climate headline\n",
            "In 4 minutes , atmospheric chemist Rachel Pike provides a glimpse of the massive scientific effort behind the bold headlines on climate change , with her team -- one of thousands who contributed -- taking a risky flight over the rainforest in pursuit of data on a key molecule .\n",
            "I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
            "Headlines that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .\n",
            "They are both two branches of the same field of atmospheric science .\n",
            "Recently the headlines looked like this when the Intergovernmental Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .\n",
            "That report was written by 620 scientists from 40 countries .\n",
            "They wrote almost a thousand pages on the topic .\n",
            "And all of those pages were reviewed by another 400-plus scientists and reviewers , from 113 countries .\n",
            "It &apos;s a big community . It &apos;s such a big community , in fact , that our annual gathering is the largest scientific meeting in the world .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD-p85hKlxo1",
        "colab_type": "code",
        "outputId": "1ee88de5-b911-4a9f-8f40-3e9e6a6cc5ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!head -10 data/train.vi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Khoa học đằng sau một tiêu đề về khí hậu\n",
            "Trong 4 phút , chuyên gia hoá học khí quyển Rachel Pike giới thiệu sơ lược về những nỗ lực khoa học miệt mài đằng sau những tiêu đề táo bạo về biến đổi khí hậu , cùng với đoàn nghiên cứu của mình -- hàng ngàn người đã cống hiến cho dự án này -- một chuyến bay mạo hiểm qua rừng già để tìm kiếm thông tin về một phân tử then chốt .\n",
            "Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
            "Có những dòng trông như thế này khi bàn về biến đổi khí hậu , và như thế này khi nói về chất lượng không khí hay khói bụi .\n",
            "Cả hai đều là một nhánh của cùng một lĩnh vực trong ngành khoa học khí quyển .\n",
            "Các tiêu đề gần đây trông như thế này khi Ban Điều hành Biến đổi khí hậu Liên chính phủ , gọi tắt là IPCC đưa ra bài nghiên cứu của họ về hệ thống khí quyển .\n",
            "Nghiên cứu được viết bởi 620 nhà khoa học từ 40 quốc gia khác nhau .\n",
            "Họ viết gần 1000 trang về chủ đề này .\n",
            "Và tất cả các trang đều được xem xét bởi 400 khoa học gia và nhà phê bình khác từ 113 quốc gia .\n",
            "Đó là cả một cộng đồng lớn , lớn đến nỗi trên thực tế cuộc tụ hội hằng năm của chúng tôi là hội nghị khoa học &#91; tự nhiên &#93; lớn nhất thế giới .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Td7xYXmFWH",
        "colab_type": "code",
        "outputId": "4997f268-ca57-4645-bbe1-eb88c44975d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "!head -10 data/vocab.vi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>\n",
            "<s>\n",
            "</s>\n",
            "Khoa\n",
            "học\n",
            "đằng\n",
            "sau\n",
            "một\n",
            "tiêu\n",
            "đề\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQf9svqSmLy2",
        "colab_type": "code",
        "outputId": "d18f33b2-e64a-4113-e34b-3fe36120bea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!hed -10 data/vocab.en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: hed: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7zs-zZTmRyx",
        "colab_type": "code",
        "outputId": "a828112d-af18-48ba-b9ab-1ea234f09041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "!apt install tree"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 66%\r\rReading package lists... 66%\r\rReading package lists... 67%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n",
            "\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 40.7 kB of archives.\n",
            "After this operation, 105 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tree amd64 1.7.0-5 [40.7 kB]\n",
            "Fetched 40.7 kB in 1s (36.9 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 135004 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_1.7.0-5_amd64.deb ...\n",
            "Unpacking tree (1.7.0-5) ...\n",
            "Setting up tree (1.7.0-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SznBb5avsVOI",
        "colab_type": "code",
        "outputId": "a9db2582-8a1b-4247-95a3-ab882a01af65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!tree ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "├── data\n",
            "│   ├── train.en\n",
            "│   ├── train.vi\n",
            "│   ├── tst2012.en\n",
            "│   ├── tst2012.vi\n",
            "│   ├── tst2013.en\n",
            "│   ├── tst2013.vi\n",
            "│   ├── vocab.en\n",
            "│   └── vocab.vi\n",
            "├── data1\n",
            "│   ├── train.en\n",
            "│   ├── train.vi\n",
            "│   ├── tst2012.en\n",
            "│   ├── tst2012.vi\n",
            "│   ├── tst2013.en\n",
            "│   ├── tst2013.vi\n",
            "│   ├── vocab.en\n",
            "│   └── vocab.vi\n",
            "├── nmt\n",
            "│   ├── CONTRIBUTING.md\n",
            "│   ├── LICENSE\n",
            "│   ├── nmt\n",
            "│   │   ├── attention_model.py\n",
            "│   │   ├── g3doc\n",
            "│   │   │   └── img\n",
            "│   │   │       ├── attention_equation_0.jpg\n",
            "│   │   │       ├── attention_equation_1.jpg\n",
            "│   │   │       ├── attention_mechanism.jpg\n",
            "│   │   │       ├── attention_vis.jpg\n",
            "│   │   │       ├── encdec.jpg\n",
            "│   │   │       ├── greedy_dec.jpg\n",
            "│   │   │       └── seq2seq.jpg\n",
            "│   │   ├── gnmt_model.py\n",
            "│   │   ├── inference.py\n",
            "│   │   ├── inference_test.py\n",
            "│   │   ├── __init__.py\n",
            "│   │   ├── model_helper.py\n",
            "│   │   ├── model.py\n",
            "│   │   ├── model_test.py\n",
            "│   │   ├── nmt.py\n",
            "│   │   ├── nmt_test.py\n",
            "│   │   ├── __pycache__\n",
            "│   │   │   ├── attention_model.cpython-36.pyc\n",
            "│   │   │   ├── gnmt_model.cpython-36.pyc\n",
            "│   │   │   ├── inference.cpython-36.pyc\n",
            "│   │   │   ├── __init__.cpython-36.pyc\n",
            "│   │   │   ├── model.cpython-36.pyc\n",
            "│   │   │   ├── model_helper.cpython-36.pyc\n",
            "│   │   │   ├── nmt.cpython-36.pyc\n",
            "│   │   │   └── train.cpython-36.pyc\n",
            "│   │   ├── scripts\n",
            "│   │   │   ├── bleu.py\n",
            "│   │   │   ├── download_iwslt15.sh\n",
            "│   │   │   ├── __init__.py\n",
            "│   │   │   ├── __pycache__\n",
            "│   │   │   │   ├── bleu.cpython-36.pyc\n",
            "│   │   │   │   ├── __init__.cpython-36.pyc\n",
            "│   │   │   │   └── rouge.cpython-36.pyc\n",
            "│   │   │   ├── rouge.py\n",
            "│   │   │   └── wmt16_en_de.sh\n",
            "│   │   ├── standard_hparams\n",
            "│   │   │   ├── iwslt15.json\n",
            "│   │   │   ├── wmt16_gnmt_4_layer.json\n",
            "│   │   │   ├── wmt16_gnmt_8_layer.json\n",
            "│   │   │   └── wmt16.json\n",
            "│   │   ├── testdata\n",
            "│   │   │   ├── deen_output\n",
            "│   │   │   ├── deen_ref_bpe\n",
            "│   │   │   ├── deen_ref_spm\n",
            "│   │   │   ├── iwslt15.tst2013.100.en\n",
            "│   │   │   ├── iwslt15.tst2013.100.vi\n",
            "│   │   │   ├── iwslt15.vocab.100.en\n",
            "│   │   │   ├── iwslt15.vocab.100.vi\n",
            "│   │   │   ├── label_ref\n",
            "│   │   │   ├── pred_output\n",
            "│   │   │   ├── test_embed.txt\n",
            "│   │   │   ├── test_embed_with_header.txt\n",
            "│   │   │   ├── test_infer_file\n",
            "│   │   │   ├── test_infer_vocab.src\n",
            "│   │   │   └── test_infer_vocab.tgt\n",
            "│   │   ├── train.py\n",
            "│   │   └── utils\n",
            "│   │       ├── common_test_utils.py\n",
            "│   │       ├── evaluation_utils.py\n",
            "│   │       ├── evaluation_utils_test.py\n",
            "│   │       ├── __init__.py\n",
            "│   │       ├── iterator_utils.py\n",
            "│   │       ├── iterator_utils_test.py\n",
            "│   │       ├── misc_utils.py\n",
            "│   │       ├── misc_utils_test.py\n",
            "│   │       ├── nmt_utils.py\n",
            "│   │       ├── __pycache__\n",
            "│   │       │   ├── evaluation_utils.cpython-36.pyc\n",
            "│   │       │   ├── __init__.cpython-36.pyc\n",
            "│   │       │   ├── iterator_utils.cpython-36.pyc\n",
            "│   │       │   ├── misc_utils.cpython-36.pyc\n",
            "│   │       │   ├── nmt_utils.cpython-36.pyc\n",
            "│   │       │   └── vocab_utils.cpython-36.pyc\n",
            "│   │       ├── standard_hparams_utils.py\n",
            "│   │       ├── vocab_utils.py\n",
            "│   │       └── vocab_utils_test.py\n",
            "│   └── README.md\n",
            "├── nmt1\n",
            "│   ├── CONTRIBUTING.md\n",
            "│   ├── LICENSE\n",
            "│   ├── nmt\n",
            "│   │   ├── attention_model.py\n",
            "│   │   ├── g3doc\n",
            "│   │   │   └── img\n",
            "│   │   │       ├── attention_equation_0.jpg\n",
            "│   │   │       ├── attention_equation_1.jpg\n",
            "│   │   │       ├── attention_mechanism.jpg\n",
            "│   │   │       ├── attention_vis.jpg\n",
            "│   │   │       ├── encdec.jpg\n",
            "│   │   │       ├── greedy_dec.jpg\n",
            "│   │   │       └── seq2seq.jpg\n",
            "│   │   ├── gnmt_model.py\n",
            "│   │   ├── inference.py\n",
            "│   │   ├── inference_test.py\n",
            "│   │   ├── __init__.py\n",
            "│   │   ├── model_helper.py\n",
            "│   │   ├── model.py\n",
            "│   │   ├── model_test.py\n",
            "│   │   ├── nmt.py\n",
            "│   │   ├── nmt_test.py\n",
            "│   │   ├── __pycache__\n",
            "│   │   │   ├── attention_model.cpython-36.pyc\n",
            "│   │   │   ├── gnmt_model.cpython-36.pyc\n",
            "│   │   │   ├── inference.cpython-36.pyc\n",
            "│   │   │   ├── __init__.cpython-36.pyc\n",
            "│   │   │   ├── model.cpython-36.pyc\n",
            "│   │   │   ├── model_helper.cpython-36.pyc\n",
            "│   │   │   ├── nmt.cpython-36.pyc\n",
            "│   │   │   └── train.cpython-36.pyc\n",
            "│   │   ├── scripts\n",
            "│   │   │   ├── bleu.py\n",
            "│   │   │   ├── download_iwslt15.sh\n",
            "│   │   │   ├── __init__.py\n",
            "│   │   │   ├── __pycache__\n",
            "│   │   │   │   ├── bleu.cpython-36.pyc\n",
            "│   │   │   │   ├── __init__.cpython-36.pyc\n",
            "│   │   │   │   └── rouge.cpython-36.pyc\n",
            "│   │   │   ├── rouge.py\n",
            "│   │   │   └── wmt16_en_de.sh\n",
            "│   │   ├── standard_hparams\n",
            "│   │   │   ├── iwslt15.json\n",
            "│   │   │   ├── wmt16_gnmt_4_layer.json\n",
            "│   │   │   ├── wmt16_gnmt_8_layer.json\n",
            "│   │   │   └── wmt16.json\n",
            "│   │   ├── testdata\n",
            "│   │   │   ├── deen_output\n",
            "│   │   │   ├── deen_ref_bpe\n",
            "│   │   │   ├── deen_ref_spm\n",
            "│   │   │   ├── iwslt15.tst2013.100.en\n",
            "│   │   │   ├── iwslt15.tst2013.100.vi\n",
            "│   │   │   ├── iwslt15.vocab.100.en\n",
            "│   │   │   ├── iwslt15.vocab.100.vi\n",
            "│   │   │   ├── label_ref\n",
            "│   │   │   ├── pred_output\n",
            "│   │   │   ├── test_embed.txt\n",
            "│   │   │   ├── test_embed_with_header.txt\n",
            "│   │   │   ├── test_infer_file\n",
            "│   │   │   ├── test_infer_vocab.src\n",
            "│   │   │   └── test_infer_vocab.tgt\n",
            "│   │   ├── train.py\n",
            "│   │   └── utils\n",
            "│   │       ├── common_test_utils.py\n",
            "│   │       ├── evaluation_utils.py\n",
            "│   │       ├── evaluation_utils_test.py\n",
            "│   │       ├── __init__.py\n",
            "│   │       ├── iterator_utils.py\n",
            "│   │       ├── iterator_utils_test.py\n",
            "│   │       ├── misc_utils.py\n",
            "│   │       ├── misc_utils_test.py\n",
            "│   │       ├── nmt_utils.py\n",
            "│   │       ├── __pycache__\n",
            "│   │       │   ├── evaluation_utils.cpython-36.pyc\n",
            "│   │       │   ├── __init__.cpython-36.pyc\n",
            "│   │       │   ├── iterator_utils.cpython-36.pyc\n",
            "│   │       │   ├── misc_utils.cpython-36.pyc\n",
            "│   │       │   ├── nmt_utils.cpython-36.pyc\n",
            "│   │       │   └── vocab_utils.cpython-36.pyc\n",
            "│   │       ├── standard_hparams_utils.py\n",
            "│   │       ├── vocab_utils.py\n",
            "│   │       └── vocab_utils_test.py\n",
            "│   └── README.md\n",
            "└── sample_data\n",
            "    ├── anscombe.json\n",
            "    ├── california_housing_test.csv\n",
            "    ├── california_housing_train.csv\n",
            "    ├── mnist_test.csv\n",
            "    ├── mnist_train_small.csv\n",
            "    └── README.md\n",
            "\n",
            "25 directories, 168 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOcsh0Nma79I",
        "colab_type": "code",
        "outputId": "922da79e-62d9-462c-9e9d-ebda4d85c5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!mkdir /tmp/nmt_attention_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/tmp/nmt_attention_model’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9gESSMAcAK3",
        "colab_type": "code",
        "outputId": "94b9ca3f-b0cb-4349-8201-6ee9a724401f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /tmp/nmt_attention_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_bleu  hparams  log_1578640477  log_1578642392  train_log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2TBH7WpcLBI",
        "colab_type": "code",
        "outputId": "4fa76dfc-02fe-4cbb-f75d-22297794c5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.en  tst2012.en  tst2013.en  vocab.en\n",
            "train.vi  tst2012.vi  tst2013.vi  vocab.vi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8SwesVwscLO",
        "colab_type": "code",
        "outputId": "e8b3c5d9-bebc-4410-c289-97463c8c692b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 -m nmt.nmt.nmt \\\n",
        "    --attention=scaled_luong \\\n",
        "    --src=vi --tgt=en \\\n",
        "    --vocab_prefix=./data/vocab  \\\n",
        "    --train_prefix=./data/train \\\n",
        "    --dev_prefix=./data/tst2012  \\\n",
        "    --test_prefix=./data/tst2013 \\\n",
        "    --out_dir=./data/nmt_attention_model \\\n",
        "    --num_train_steps=12000 \\\n",
        "    --steps_per_stats=100 \\\n",
        "    --num_layers=2 \\\n",
        "    --num_units=128 \\\n",
        "    --dropout=0.2 \\\n",
        "    --metrics=bleu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:707: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "I0110 07:54:27.266627 139680480475008 utils.py:141] NumExpr defaulting to 2 threads.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0110 07:54:27.602888 139680480475008 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "# Job id 0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:629: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0110 07:54:27.603313 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/nmt.py:629: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-01-10 07:54:27.604158: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-01-10 07:54:27.608920: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-01-10 07:54:27.609153: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19d4840 executing computations on platform Host. Devices:\n",
            "2020-01-10 07:54:27.609194: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "# Devices visible to TensorFlow: [_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 6697855621044655127), _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 8369021654117521215)]\n",
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:640: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "W0110 07:54:27.609859 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/nmt.py:640: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "# Creating output directory ./data/nmt_attention_model ...\n",
            "WARNING:tensorflow:From /content/nmt/nmt/nmt.py:642: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0110 07:54:27.610130 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/nmt.py:642: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "# Vocab file ./data/vocab.vi exists\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/vocab_utils.py:103: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0110 07:54:27.610489 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/utils/vocab_utils.py:103: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "# Vocab file ./data/vocab.en exists\n",
            "  saving hparams to ./data/nmt_attention_model/hparams\n",
            "  saving hparams to ./data/nmt_attention_model/best_bleu/hparams\n",
            "  attention=scaled_luong\n",
            "  attention_architecture=standard\n",
            "  avg_ckpts=False\n",
            "  batch_size=128\n",
            "  beam_width=0\n",
            "  best_bleu=0\n",
            "  best_bleu_dir=./data/nmt_attention_model/best_bleu\n",
            "  check_special_token=True\n",
            "  colocate_gradients_with_ops=True\n",
            "  coverage_penalty_weight=0.0\n",
            "  decay_scheme=\n",
            "  dev_prefix=./data/tst2012\n",
            "  dropout=0.2\n",
            "  embed_prefix=None\n",
            "  encoder_type=uni\n",
            "  eos=</s>\n",
            "  epoch_step=0\n",
            "  forget_bias=1.0\n",
            "  infer_batch_size=32\n",
            "  infer_mode=greedy\n",
            "  init_op=uniform\n",
            "  init_weight=0.1\n",
            "  language_model=False\n",
            "  learning_rate=1.0\n",
            "  length_penalty_weight=0.0\n",
            "  log_device_placement=False\n",
            "  max_gradient_norm=5.0\n",
            "  max_train=0\n",
            "  metrics=['bleu']\n",
            "  num_buckets=5\n",
            "  num_dec_emb_partitions=0\n",
            "  num_decoder_layers=2\n",
            "  num_decoder_residual_layers=0\n",
            "  num_embeddings_partitions=0\n",
            "  num_enc_emb_partitions=0\n",
            "  num_encoder_layers=2\n",
            "  num_encoder_residual_layers=0\n",
            "  num_gpus=1\n",
            "  num_inter_threads=0\n",
            "  num_intra_threads=0\n",
            "  num_keep_ckpts=5\n",
            "  num_sampled_softmax=0\n",
            "  num_train_steps=12000\n",
            "  num_translations_per_input=1\n",
            "  num_units=128\n",
            "  optimizer=sgd\n",
            "  out_dir=./data/nmt_attention_model\n",
            "  output_attention=True\n",
            "  override_loaded_hparams=False\n",
            "  pass_hidden_state=True\n",
            "  random_seed=None\n",
            "  residual=False\n",
            "  sampling_temperature=0.0\n",
            "  share_vocab=False\n",
            "  sos=<s>\n",
            "  src=vi\n",
            "  src_embed_file=\n",
            "  src_max_len=50\n",
            "  src_max_len_infer=None\n",
            "  src_vocab_file=./data/vocab.vi\n",
            "  src_vocab_size=7709\n",
            "  steps_per_external_eval=None\n",
            "  steps_per_stats=100\n",
            "  subword_option=\n",
            "  test_prefix=./data/tst2013\n",
            "  tgt=en\n",
            "  tgt_embed_file=\n",
            "  tgt_max_len=50\n",
            "  tgt_max_len_infer=None\n",
            "  tgt_vocab_file=./data/vocab.en\n",
            "  tgt_vocab_size=17191\n",
            "  time_major=True\n",
            "  train_prefix=./data/train\n",
            "  unit_type=lstm\n",
            "  use_char_encode=False\n",
            "  vocab_prefix=./data/vocab\n",
            "  warmup_scheme=t2t\n",
            "  warmup_steps=0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:90: The name tf.container is deprecated. Please use tf.compat.v1.container instead.\n",
            "\n",
            "W0110 07:54:27.649817 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model_helper.py:90: The name tf.container is deprecated. Please use tf.compat.v1.container instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:94: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0110 07:54:27.657322 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model_helper.py:94: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:96: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0110 07:54:27.684434 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model_helper.py:96: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.group_by_window(...)`.\n",
            "W0110 07:54:27.866579 139680480475008 deprecation.py:323] From /content/nmt/nmt/utils/iterator_utils.py:235: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.group_by_window(...)`.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0110 07:54:27.874249 139680480475008 deprecation.py:323] From /content/nmt/nmt/utils/iterator_utils.py:228: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/utils/iterator_utils.py:239: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W0110 07:54:27.895476 139680480475008 deprecation.py:323] From /content/nmt/nmt/utils/iterator_utils.py:239: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:162: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0110 07:54:27.905267 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model.py:162: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0110 07:54:27.905506 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model_helper.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "# Creating train graph ...\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:375: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "W0110 07:54:27.920848 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model.py:375: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
            "\n",
            "# Build a basic encoder\n",
            "  num_layers = 2, num_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0110 07:54:27.924966 139680480475008 deprecation.py:323] From /content/nmt/nmt/model_helper.py:402: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0110 07:54:27.930100 139680480475008 deprecation.py:323] From /content/nmt/nmt/model_helper.py:508: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:767: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0110 07:54:27.930479 139680480475008 deprecation.py:323] From /content/nmt/nmt/model.py:767: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0110 07:54:28.251046 139680480475008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0110 07:54:28.602331 139680480475008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0110 07:54:28.629822 139680480475008 deprecation.py:323] From /content/nmt/nmt/model.py:445: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:445: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0110 07:54:28.632350 139680480475008 deprecation.py:323] From /content/nmt/nmt/model.py:445: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "  cell 0  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DropoutWrapper, dropout=0.2   DeviceWrapper, device=/gpu:0\n",
            "  learning_rate=1, warmup_steps=0, warmup_scheme=t2t\n",
            "  decay_scheme=, start_decay_step=12000, decay_steps 0, decay_factor 1\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:295: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0110 07:54:29.907030 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model.py:295: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:203: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "W0110 07:54:29.915976 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model.py:203: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model_helper.py:515: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0110 07:54:31.355941 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model_helper.py:515: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:321: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0110 07:54:31.389621 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model.py:321: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0\n",
            "WARNING:tensorflow:From /content/nmt/nmt/model.py:100: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0110 07:54:31.393212 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/model.py:100: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "# Creating eval graph ...\n",
            "# Build a basic encoder\n",
            "  num_layers = 2, num_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), /device:GPU:0\n",
            "# Creating infer graph ...\n",
            "# Build a basic encoder\n",
            "  num_layers = 2, num_residual_layers=0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 0  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  cell 1  LSTM, forget_bias=1  DeviceWrapper, device=/gpu:0\n",
            "  decoder: infer_mode=greedybeam_width=0, length_penalty=0.000000, coverage_penalty=0.000000\n",
            "WARNING:tensorflow:From /content/nmt/nmt/attention_model.py:193: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0110 07:54:33.073066 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/attention_model.py:193: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "# Trainable variables\n",
            "Format: <name>, <shape>, <(soft) device placement>\n",
            "  embeddings/encoder/embedding_encoder:0, (7709, 128), /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder:0, (17191, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (128, 128), \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0, (384, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (256, 512), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (512,), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g:0, (), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel:0, (256, 128), /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel:0, (128, 17191), \n",
            "# log_file=./data/nmt_attention_model/log_1578642873\n",
            "2020-01-10 07:54:33.148058: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "ConcatV2: CPU XLA_CPU \n",
            "ScatterSub: CPU \n",
            "StridedSlice: CPU XLA_CPU \n",
            "Size: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ExpandDims: CPU XLA_CPU \n",
            "GatherV2: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "L2Loss: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Reshape: CPU XLA_CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "Assign: CPU \n",
            "Cast: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/shape (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/min (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/max (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/sub (Sub) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/mul (Mul) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform (Add) \n",
            "  embeddings/encoder/embedding_encoder (VariableV2) /device:GPU:0\n",
            "  embeddings/encoder/embedding_encoder/Assign (Assign) /device:GPU:0\n",
            "  embeddings/encoder/embedding_encoder/read (Identity) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/embedding_lookup/axis (Const) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/embedding_lookup (GatherV2) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/Shape (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/Cast (Cast) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/Size (Size) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/ExpandDims/dim (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/ExpandDims (ExpandDims) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/strided_slice/stack (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/strided_slice/stack_1 (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/strided_slice/stack_2 (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/strided_slice (StridedSlice) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/concat/axis (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/concat (ConcatV2) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/Reshape (Reshape) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/encoder/embedding_lookup_grad/Reshape_1 (Reshape) /device:GPU:0\n",
            "  global_norm/L2Loss (L2Loss) /device:GPU:0\n",
            "  clip_by_global_norm/mul_1 (Mul) /device:GPU:0\n",
            "  clip_by_global_norm/clip_by_global_norm/_0 (Identity) /device:GPU:0\n",
            "  global_norm_1/L2Loss (L2Loss) /device:GPU:0\n",
            "  GradientDescent/update_embeddings/encoder/embedding_encoder/mul (Mul) /device:GPU:0\n",
            "  GradientDescent/update_embeddings/encoder/embedding_encoder/ScatterSub (ScatterSub) /device:GPU:0\n",
            "  save/Assign_14 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.148263: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "ConcatV2: CPU XLA_CPU \n",
            "ScatterSub: CPU \n",
            "StridedSlice: CPU XLA_CPU \n",
            "Size: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ExpandDims: CPU XLA_CPU \n",
            "GatherV2: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "L2Loss: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Reshape: CPU XLA_CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "Assign: CPU \n",
            "Cast: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/shape (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/min (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/max (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/sub (Sub) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/mul (Mul) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform (Add) \n",
            "  embeddings/decoder/embedding_decoder (VariableV2) /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder/Assign (Assign) /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder/read (Identity) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/embedding_lookup/axis (Const) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/embedding_lookup (GatherV2) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/Shape (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/Cast (Cast) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/Size (Size) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/ExpandDims/dim (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/ExpandDims (ExpandDims) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/strided_slice/stack (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/strided_slice/stack_1 (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/strided_slice/stack_2 (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/strided_slice (StridedSlice) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/concat/axis (Const) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/concat (ConcatV2) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/Reshape (Reshape) /device:GPU:0\n",
            "  gradients/dynamic_seq2seq/decoder/embedding_lookup_grad/Reshape_1 (Reshape) /device:GPU:0\n",
            "  global_norm/L2Loss_1 (L2Loss) /device:GPU:0\n",
            "  clip_by_global_norm/mul_2 (Mul) /device:GPU:0\n",
            "  clip_by_global_norm/clip_by_global_norm/_1 (Identity) /device:GPU:0\n",
            "  global_norm_1/L2Loss_1 (L2Loss) /device:GPU:0\n",
            "  GradientDescent/update_embeddings/decoder/embedding_decoder/mul (Mul) /device:GPU:0\n",
            "  GradientDescent/update_embeddings/decoder/embedding_decoder/ScatterSub (ScatterSub) /device:GPU:0\n",
            "  save/Assign_13 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.148475: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_10 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.148555: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_9 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.148651: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_12 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.148732: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_11 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.149091: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_4 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.186937: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_3 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.187254: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_6 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.187408: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_5 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.187588: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g/Initializer/ones (Const) \n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/decoder/attention/luong_attention/attention_g/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_2 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.187836: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Assign (Assign) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/decoder/attention/attention_layer/kernel/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_1 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.188127: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "ApplyGradientDescent: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Assign (Assign) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/read (Identity) /device:GPU:0\n",
            "  GradientDescent/update_dynamic_seq2seq/decoder/output_projection/kernel/ApplyGradientDescent (ApplyGradientDescent) /device:GPU:0\n",
            "  save/Assign_8 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.239568: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "  created train model with fresh parameters, time 0.28s\n",
            "WARNING:tensorflow:From /content/nmt/nmt/train.py:500: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "W0110 07:54:33.407694 139680480475008 deprecation_wrapper.py:119] From /content/nmt/nmt/train.py:500: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "2020-01-10 07:54:33.737649: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "GatherV2: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/shape (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/min (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/max (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/sub (Sub) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/mul (Mul) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform (Add) \n",
            "  embeddings/encoder/embedding_encoder (VariableV2) /device:GPU:0\n",
            "  embeddings/encoder/embedding_encoder/Assign (Assign) /device:GPU:0\n",
            "  embeddings/encoder/embedding_encoder/read (Identity) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/embedding_lookup/axis (Const) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/embedding_lookup (GatherV2) /device:GPU:0\n",
            "  save/Assign_14 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.737819: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "RandomUniform: CPU XLA_CPU \n",
            "GatherV2: CPU XLA_CPU \n",
            "Enter: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "Switch: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "Assign: CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/shape (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/min (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/max (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/sub (Sub) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/mul (Mul) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform (Add) \n",
            "  embeddings/decoder/embedding_decoder (VariableV2) /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder/Assign (Assign) /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder/read (Identity) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/embedding_lookup/axis (Const) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/embedding_lookup (GatherV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/decoder/while/BasicDecoderStep/cond/embedding_lookup/axis (Const) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/decoder/while/BasicDecoderStep/cond/embedding_lookup/Enter (Enter) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/decoder/while/BasicDecoderStep/cond/embedding_lookup/Switch (Switch) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/decoder/while/BasicDecoderStep/cond/embedding_lookup (GatherV2) /device:GPU:0\n",
            "  save/Assign_13 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.737989: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_10 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.738047: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_9 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.738148: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_12 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.738200: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_11 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.738571: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_4 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.738627: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_3 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.738732: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_6 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.796267: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_5 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.796471: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g/Initializer/ones (Const) \n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_2 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:33.796676: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_1 (Assign) /device:GPU:0\n",
            "\n",
            "  created infer model with fresh parameters, time 0.18s\n",
            "  # 770\n",
            "    src: Và trong một ngày nhiều mây , có khe hở giữa các đám mây và mặt trời ló dạng và tôi thắc mắc , chắc là tôi có thể cảm thấy khá hơn một lần nữa .\n",
            "    ref: And on a cloudy day , there was a crack in the clouds and the sun started to come out and I wondered , maybe I could feel better again .\n",
            "    nmt: center center center heal heal spontaneous spontaneous spontaneous emperor emperor strength strength Eat merely merely staple staple staple sunk sunk sunk sunk sunk sunk Yo Yo S S S S lent sizes invasive invasive invasive non-violent non-violent non-violent emphasized emphasized emphasized passions passions passions passions passions passions Dalai Dalai famous famous famous Stygimoloch Stygimoloch Stygimoloch Bang reply reply destroy Bergen Bergen retinal retinal retinal retinal silver silver weekday devastating persuasive persuasive persuasive persuasive persuasive\n",
            "2020-01-10 07:54:34.209729: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "GatherV2: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/shape (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/min (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/max (Const) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/sub (Sub) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform/mul (Mul) \n",
            "  embeddings/encoder/embedding_encoder/Initializer/random_uniform (Add) \n",
            "  embeddings/encoder/embedding_encoder (VariableV2) /device:GPU:0\n",
            "  embeddings/encoder/embedding_encoder/Assign (Assign) /device:GPU:0\n",
            "  embeddings/encoder/embedding_encoder/read (Identity) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/embedding_lookup/axis (Const) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/embedding_lookup (GatherV2) /device:GPU:0\n",
            "  save/Assign_14 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.209874: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "GatherV2: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/shape (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/min (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/max (Const) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/sub (Sub) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform/mul (Mul) \n",
            "  embeddings/decoder/embedding_decoder/Initializer/random_uniform (Add) \n",
            "  embeddings/decoder/embedding_decoder (VariableV2) /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder/Assign (Assign) /device:GPU:0\n",
            "  embeddings/decoder/embedding_decoder/read (Identity) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/embedding_lookup/axis (Const) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/embedding_lookup (GatherV2) /device:GPU:0\n",
            "  save/Assign_13 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.210106: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_10 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.210185: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_9 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.210294: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_12 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.210355: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_11 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.210933: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_4 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.211033: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_0/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_3 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.211150: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_6 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.211219: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Initializer/zeros (Const) \n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/multi_rnn_cell/cell_1/basic_lstm_cell/bias/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_5 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.211326: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g/Initializer/ones (Const) \n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/luong_attention/attention_g/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_2 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.301474: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/attention/attention_layer/kernel/Assign (Assign) /device:GPU:0\n",
            "  save/Assign_1 (Assign) /device:GPU:0\n",
            "\n",
            "2020-01-10 07:54:34.302375: W tensorflow/core/common_runtime/colocation_graph.cc:1016] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n",
            "  /job:localhost/replica:0/task:0/device:CPU:0].\n",
            "See below for details of this colocation group:\n",
            "Colocation Debug Info:\n",
            "Colocation group had the following types and supported devices: \n",
            "Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\n",
            "Assign: CPU \n",
            "Identity: CPU XLA_CPU \n",
            "VariableV2: CPU \n",
            "Mul: CPU XLA_CPU \n",
            "Add: CPU XLA_CPU \n",
            "Sub: CPU XLA_CPU \n",
            "RandomUniform: CPU XLA_CPU \n",
            "Const: CPU XLA_CPU \n",
            "\n",
            "Colocation members, user-requested devices, and framework assigned devices, if any:\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/shape (Const) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/min (Const) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/max (Const) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/RandomUniform (RandomUniform) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/sub (Sub) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform/mul (Mul) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Initializer/random_uniform (Add) \n",
            "  dynamic_seq2seq/decoder/output_projection/kernel (VariableV2) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/Assign (Assign) /device:GPU:0\n",
            "  dynamic_seq2seq/decoder/output_projection/kernel/read (Identity) /device:GPU:0\n",
            "  save/Assign_8 (Assign) /device:GPU:0\n",
            "\n",
            "  created eval model with fresh parameters, time 0.24s\n",
            "2020-01-10 07:54:38.781422: W tensorflow/core/framework/allocator.cc:107] Allocation of 343269888 exceeds 10% of system memory.\n",
            "2020-01-10 07:54:45.316862: W tensorflow/core/framework/allocator.cc:107] Allocation of 320096420 exceeds 10% of system memory.\n",
            "2020-01-10 07:54:46.876691: W tensorflow/core/framework/allocator.cc:107] Allocation of 446003304 exceeds 10% of system memory.\n",
            "  eval dev: perplexity 17197.77, time 13s, Fri Jan 10 07:54:48 2020.\n",
            "2020-01-10 07:54:51.354553: W tensorflow/core/framework/allocator.cc:107] Allocation of 325666304 exceeds 10% of system memory.\n",
            "2020-01-10 07:54:56.225169: W tensorflow/core/framework/allocator.cc:107] Allocation of 381365144 exceeds 10% of system memory.\n",
            "  eval test: perplexity 17196.02, time 12s, Fri Jan 10 07:55:01 2020.\n",
            "2020-01-10 07:55:01.388829: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 07:55:01.388829: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 07:55:01.389011: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.vi is already initialized.\n",
            "  created infer model with fresh parameters, time 0.13s\n",
            "# Start step 0, lr 1, Fri Jan 10 07:55:01 2020\n",
            "# Init train iterator, skipping 0 elements\n",
            "  step 100 lr 1 step-time 2.19s wps 2.55K ppl 17091.24 gN 73.58 bleu 0.00, Fri Jan 10 07:58:40 2020\n",
            "  step 200 lr 1 step-time 2.01s wps 2.81K ppl 1377.35 gN 20.09 bleu 0.00, Fri Jan 10 08:02:01 2020\n",
            "  step 300 lr 1 step-time 2.00s wps 2.80K ppl 630.49 gN 8.05 bleu 0.00, Fri Jan 10 08:05:21 2020\n",
            "  step 400 lr 1 step-time 2.03s wps 2.82K ppl 523.03 gN 6.86 bleu 0.00, Fri Jan 10 08:08:44 2020\n",
            "  step 500 lr 1 step-time 1.98s wps 2.79K ppl 399.95 gN 5.41 bleu 0.00, Fri Jan 10 08:12:02 2020\n",
            "  step 600 lr 1 step-time 2.00s wps 2.80K ppl 340.01 gN 5.01 bleu 0.00, Fri Jan 10 08:15:22 2020\n",
            "  step 700 lr 1 step-time 2.01s wps 2.81K ppl 290.97 gN 4.84 bleu 0.00, Fri Jan 10 08:18:43 2020\n",
            "  step 800 lr 1 step-time 2.02s wps 2.81K ppl 255.47 gN 5.24 bleu 0.00, Fri Jan 10 08:22:05 2020\n",
            "  step 900 lr 1 step-time 1.97s wps 2.80K ppl 215.01 gN 3.91 bleu 0.00, Fri Jan 10 08:25:22 2020\n",
            "  step 1000 lr 1 step-time 2.02s wps 2.81K ppl 202.83 gN 4.06 bleu 0.00, Fri Jan 10 08:28:44 2020\n",
            "# Save eval, global step 1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0110 08:28:44.693076 139680480475008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "I0110 08:28:44.694474 139680480475008 saver.py:1280] Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "2020-01-10 08:28:44.777418: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 08:28:44.777636: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 08:28:44.777851: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.vi is already initialized.\n",
            "  loaded infer model parameters from ./data/nmt_attention_model/translate.ckpt-1000, time 0.09s\n",
            "  # 1332\n",
            "    src: Vào tuần tới , một thiết bị sẽ sớm được ra mắt .\n",
            "    ref: As of next week , it will soon be available .\n",
            "    nmt: And I had a lot of a lot of <unk> .\n",
            "INFO:tensorflow:Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "I0110 08:28:44.804888 139680480475008 saver.py:1280] Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "2020-01-10 08:28:44.895852: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 08:28:44.895971: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.vi is already initialized.\n",
            "2020-01-10 08:28:44.896012: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "  loaded eval model parameters from ./data/nmt_attention_model/translate.ckpt-1000, time 0.09s\n",
            "  eval dev: perplexity 169.88, time 12s, Fri Jan 10 08:28:57 2020.\n",
            "  eval test: perplexity 200.77, time 12s, Fri Jan 10 08:29:10 2020.\n",
            "# Finished an epoch, step 1043. Perform external evaluation\n",
            "INFO:tensorflow:Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "I0110 08:30:32.133483 139680480475008 saver.py:1280] Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "2020-01-10 08:30:32.190575: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 08:30:32.190694: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.vi is already initialized.\n",
            "2020-01-10 08:30:32.190789: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "  loaded infer model parameters from ./data/nmt_attention_model/translate.ckpt-1000, time 0.06s\n",
            "  # 389\n",
            "    src: Vậy anh đã nghe và đã thấy được mong muốn của quý vị khán giả , cuả cộng đồng TED để giúp anh trên con đường của mình và làm được điều gì đó đối với vấn đề này .\n",
            "    ref: So you heard and saw an obvious desire by this audience , this community , to help you on your way and to do something on this issue .\n",
            "    nmt: And I had a lot of a lot of <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> .\n",
            "INFO:tensorflow:Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "I0110 08:30:32.235214 139680480475008 saver.py:1280] Restoring parameters from ./data/nmt_attention_model/translate.ckpt-1000\n",
            "2020-01-10 08:30:32.291149: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 08:30:32.291149: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.en is already initialized.\n",
            "2020-01-10 08:30:32.291293: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file ./data/vocab.vi is already initialized.\n",
            "  loaded infer model parameters from ./data/nmt_attention_model/translate.ckpt-1000, time 0.06s\n",
            "# External evaluation, global step 1000\n",
            "  decoding to output ./data/nmt_attention_model/output_dev\n",
            "  done, num sentences 1553, num translations per input 1, time 20s, Fri Jan 10 08:30:53 2020.\n",
            "  bleu dev: 0.3\n",
            "  saving hparams to ./data/nmt_attention_model/hparams\n",
            "# External evaluation, global step 1000\n",
            "  decoding to output ./data/nmt_attention_model/output_test\n",
            "  done, num sentences 1268, num translations per input 1, time 20s, Fri Jan 10 08:31:14 2020.\n",
            "  bleu test: 0.2\n",
            "  saving hparams to ./data/nmt_attention_model/hparams\n",
            "  step 1100 lr 1 step-time 2.12s wps 2.54K ppl 186.27 gN 4.01 bleu 0.26, Fri Jan 10 08:33:23 2020\n",
            "  step 1200 lr 1 step-time 2.00s wps 2.80K ppl 181.66 gN 4.05 bleu 0.26, Fri Jan 10 08:36:44 2020\n",
            "  step 1300 lr 1 step-time 2.04s wps 2.79K ppl 168.13 gN 3.73 bleu 0.26, Fri Jan 10 08:40:08 2020\n",
            "  step 1400 lr 1 step-time 2.01s wps 2.79K ppl 157.24 gN 3.59 bleu 0.26, Fri Jan 10 08:43:28 2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBJd_OdKetQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSgLqrxYuLr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ptu9ShxuzeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1B_DjpXvESO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnyk3b1mvVW2",
        "colab_type": "code",
        "outputId": "13bde97e-1c4e-43d2-fdfc-da9ab3feb11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD24cbqRI3yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}